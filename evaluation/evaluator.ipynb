{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6918560,"sourceType":"datasetVersion","datasetId":3972653},{"sourceId":7163024,"sourceType":"datasetVersion","datasetId":4137525}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport codecs, json","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-10T08:32:10.986466Z","iopub.execute_input":"2023-12-10T08:32:10.986898Z","iopub.status.idle":"2023-12-10T08:32:10.993495Z","shell.execute_reply.started":"2023-12-10T08:32:10.986834Z","shell.execute_reply":"2023-12-10T08:32:10.992226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/summarization-set/full_cleaned.csv\"","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:32:10.998518Z","iopub.execute_input":"2023-12-10T08:32:10.998931Z","iopub.status.idle":"2023-12-10T08:32:11.008417Z","shell.execute_reply.started":"2023-12-10T08:32:10.998895Z","shell.execute_reply":"2023-12-10T08:32:11.007272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(path)\ndf.head()\noriginal_dataset_size = len(df[\"news\"])","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:32:11.010710Z","iopub.execute_input":"2023-12-10T08:32:11.011218Z","iopub.status.idle":"2023-12-10T08:32:47.738425Z","shell.execute_reply.started":"2023-12-10T08:32:11.011176Z","shell.execute_reply":"2023-12-10T08:32:47.736047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.isnull().sum())\ndf.drop_duplicates(subset=['title', 'news'], inplace=True)\ndf[\"title_length\"] = df[\"title\"].apply(lambda x: len(x.split()))\ndf[\"news_length\"] = df[\"news\"].apply(lambda x: len(x.split()))\ndf = df[df[\"title_length\"] > 2]\ndf = df[df[\"news_length\"] >= 30]\ndf = df[df[\"news_length\"] <= 400]","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:32:47.740978Z","iopub.execute_input":"2023-12-10T08:32:47.742428Z","iopub.status.idle":"2023-12-10T08:33:03.404995Z","shell.execute_reply.started":"2023-12-10T08:32:47.742382Z","shell.execute_reply":"2023-12-10T08:33:03.403672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with codecs.open('/kaggle/input/model-output/kaggle/working/constants.json', encoding='utf-8') as const:\n    CONSTANTS = json.load(const)\nCONSTANTS","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:03.463122Z","iopub.execute_input":"2023-12-10T08:33:03.463633Z","iopub.status.idle":"2023-12-10T08:33:03.480657Z","shell.execute_reply.started":"2023-12-10T08:33:03.463597Z","shell.execute_reply":"2023-12-10T08:33:03.479098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"title_cut\"] = df[\"title\"].apply(lambda x: \" \".join(x.split()[:CONSTANTS[\"max_title_length\"]]))\ndf[\"news_cut\"] = df[\"news\"].apply(lambda x: \" \".join(x.split()[:CONSTANTS[\"max_news_length\"]]))","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:03.483551Z","iopub.execute_input":"2023-12-10T08:33:03.483985Z","iopub.status.idle":"2023-12-10T08:33:12.748143Z","shell.execute_reply.started":"2023-12-10T08:33:03.483950Z","shell.execute_reply":"2023-12-10T08:33:12.746907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"title_cut\"] = df[\"title_cut\"].apply(lambda x: 'sos ' + x + ' eos')","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:12.749866Z","iopub.execute_input":"2023-12-10T08:33:12.750224Z","iopub.status.idle":"2023-12-10T08:33:13.069308Z","shell.execute_reply.started":"2023-12-10T08:33:12.750195Z","shell.execute_reply":"2023-12-10T08:33:13.068106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:13.070812Z","iopub.execute_input":"2023-12-10T08:33:13.071636Z","iopub.status.idle":"2023-12-10T08:33:13.076916Z","shell.execute_reply.started":"2023-12-10T08:33:13.071600Z","shell.execute_reply":"2023-12-10T08:33:13.075594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val_test, y_train, y_val_test = train_test_split(df.drop(['title', 'title_cut', 'title_length', 'news_length', 'category'], axis=1), df.drop(['news', 'news_cut', 'title_length', 'news_length', 'category'], axis=1), test_size=0.2, random_state=21, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:13.078810Z","iopub.execute_input":"2023-12-10T08:33:13.079795Z","iopub.status.idle":"2023-12-10T08:33:14.601101Z","shell.execute_reply.started":"2023-12-10T08:33:13.079757Z","shell.execute_reply":"2023-12-10T08:33:14.599678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=21, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:14.603463Z","iopub.execute_input":"2023-12-10T08:33:14.603937Z","iopub.status.idle":"2023-12-10T08:33:15.065945Z","shell.execute_reply.started":"2023-12-10T08:33:14.603896Z","shell.execute_reply":"2023-12-10T08:33:15.064620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Length of dataset: {len(df['title'])}, in %: {len(df['title']) / len(df['title']) * 100}\")\nprint(f\"Length of training set: {len(X_train['news'])}, in %: {len(X_train['news']) / len(df['title']) * 100}\")\nprint(f\"Length of validation set: {len(X_val['news'])}, in %: {len(X_val['news']) / len(df['title']) * 100}\")\nprint(f\"Length of test set: {len(X_test['news'])}, in %: {len(X_test['news']) / len(df['title']) * 100}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:15.746255Z","iopub.execute_input":"2023-12-10T08:33:15.747335Z","iopub.status.idle":"2023-12-10T08:33:15.755596Z","shell.execute_reply.started":"2023-12-10T08:33:15.747291Z","shell.execute_reply":"2023-12-10T08:33:15.754377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:15.762792Z","iopub.execute_input":"2023-12-10T08:33:15.763888Z","iopub.status.idle":"2023-12-10T08:33:15.771653Z","shell.execute_reply.started":"2023-12-10T08:33:15.763830Z","shell.execute_reply":"2023-12-10T08:33:15.768691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json, codecs\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nwith codecs.open('/kaggle/input/model-output/kaggle/working/X_tokenizer.json', encoding='utf-8') as f:\n    data = json.load(f)\n    X_tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(data)\n\nwith codecs.open('/kaggle/input/model-output/kaggle/working/target_tokenizer.json', encoding='utf-8') as f:\n    data = json.load(f)\n    y_tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(data)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:15.774541Z","iopub.execute_input":"2023-12-10T08:33:15.775120Z","iopub.status.idle":"2023-12-10T08:33:33.063148Z","shell.execute_reply.started":"2023-12-10T08:33:15.775073Z","shell.execute_reply":"2023-12-10T08:33:33.062163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_tokenizer.sequences_to_texts([[10, 12, 100, 100000, 10, 0]])","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:33.064825Z","iopub.execute_input":"2023-12-10T08:33:33.065575Z","iopub.status.idle":"2023-12-10T08:33:33.074564Z","shell.execute_reply.started":"2023-12-10T08:33:33.065539Z","shell.execute_reply":"2023-12-10T08:33:33.073134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_seq = X_tokenizer.texts_to_sequences(X_test[\"news_cut\"])\n\nX_test_pad_seq = pad_sequences(X_test_seq, maxlen=CONSTANTS[\"max_news_length\"], padding='post')","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:33.076030Z","iopub.execute_input":"2023-12-10T08:33:33.076417Z","iopub.status.idle":"2023-12-10T08:33:42.585042Z","shell.execute_reply.started":"2023-12-10T08:33:33.076387Z","shell.execute_reply":"2023-12-10T08:33:42.583186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_voc_size = len(X_tokenizer.word_index) + 1\nX_voc_size","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:42.586883Z","iopub.execute_input":"2023-12-10T08:33:42.588177Z","iopub.status.idle":"2023-12-10T08:33:42.596451Z","shell.execute_reply.started":"2023-12-10T08:33:42.588127Z","shell.execute_reply":"2023-12-10T08:33:42.595221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_seq = y_tokenizer.texts_to_sequences(y_test[\"title_cut\"])\n\ny_test_padded_seq = pad_sequences(y_test_seq, maxlen=CONSTANTS[\"max_title_length\"], padding='post')","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:42.598198Z","iopub.execute_input":"2023-12-10T08:33:42.598805Z","iopub.status.idle":"2023-12-10T08:33:43.552046Z","shell.execute_reply.started":"2023-12-10T08:33:42.598760Z","shell.execute_reply":"2023-12-10T08:33:43.550558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_voc_size = len(y_tokenizer.word_index) + 1\ny_voc_size","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:43.553622Z","iopub.execute_input":"2023-12-10T08:33:43.554002Z","iopub.status.idle":"2023-12-10T08:33:43.561221Z","shell.execute_reply.started":"2023-12-10T08:33:43.553971Z","shell.execute_reply":"2023-12-10T08:33:43.560292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:43.562899Z","iopub.execute_input":"2023-12-10T08:33:43.563376Z","iopub.status.idle":"2023-12-10T08:33:43.573749Z","shell.execute_reply.started":"2023-12-10T08:33:43.563340Z","shell.execute_reply":"2023-12-10T08:33:43.572369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/model-output/kaggle/working/train_history.pkl', \"rb\") as hist:\n    history = pickle.load(hist)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:43.574973Z","iopub.execute_input":"2023-12-10T08:33:43.575340Z","iopub.status.idle":"2023-12-10T08:33:43.587640Z","shell.execute_reply.started":"2023-12-10T08:33:43.575310Z","shell.execute_reply":"2023-12-10T08:33:43.586167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history['accuracy'])\nplt.plot(history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:43.589770Z","iopub.execute_input":"2023-12-10T08:33:43.590257Z","iopub.status.idle":"2023-12-10T08:33:43.954604Z","shell.execute_reply.started":"2023-12-10T08:33:43.590223Z","shell.execute_reply":"2023-12-10T08:33:43.953314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history['loss'])\nplt.plot(history['val_loss'])\nplt.title('training loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:43.956259Z","iopub.execute_input":"2023-12-10T08:33:43.956684Z","iopub.status.idle":"2023-12-10T08:33:44.283966Z","shell.execute_reply.started":"2023-12-10T08:33:43.956649Z","shell.execute_reply":"2023-12-10T08:33:44.282649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Bidirectional, LSTM, Input, Dense, TimeDistributed, Embedding, Concatenate\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.layers import Input","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:44.285537Z","iopub.execute_input":"2023-12-10T08:33:44.285921Z","iopub.status.idle":"2023-12-10T08:33:44.294791Z","shell.execute_reply.started":"2023-12-10T08:33:44.285889Z","shell.execute_reply":"2023-12-10T08:33:44.293081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !unzip \"/kaggle/input/pretrained/file.zip\"","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:44.296403Z","iopub.execute_input":"2023-12-10T08:33:44.296775Z","iopub.status.idle":"2023-12-10T08:33:44.304222Z","shell.execute_reply.started":"2023-12-10T08:33:44.296746Z","shell.execute_reply":"2023-12-10T08:33:44.302610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.load_model('/kaggle/input/model-output/kaggle/working/Nepali_News_Headline_Gen_Model')","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:44.306231Z","iopub.execute_input":"2023-12-10T08:33:44.306712Z","iopub.status.idle":"2023-12-10T08:33:58.198521Z","shell.execute_reply.started":"2023-12-10T08:33:44.306669Z","shell.execute_reply":"2023-12-10T08:33:58.197394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, to_file='inf_encoder_nepali_news_headline_generation_model.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:58.370615Z","iopub.execute_input":"2023-12-10T08:33:58.371137Z","iopub.status.idle":"2023-12-10T08:33:58.564585Z","shell.execute_reply.started":"2023-12-10T08:33:58.371102Z","shell.execute_reply":"2023-12-10T08:33:58.563269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## INFERENCE MODEL","metadata":{}},{"cell_type":"markdown","source":"The training model won't work for us, since we are using teacher forcing to train our model.<br>\n\nSo during inference, we need to build our inference model from the start.","metadata":{}},{"cell_type":"markdown","source":"Lets take a look the layers in our model","metadata":{}},{"cell_type":"code","source":"[layer.name for layer in model.layers]","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:58.566065Z","iopub.execute_input":"2023-12-10T08:33:58.566439Z","iopub.status.idle":"2023-12-10T08:33:58.575166Z","shell.execute_reply.started":"2023-12-10T08:33:58.566409Z","shell.execute_reply":"2023-12-10T08:33:58.573701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inf_encoder_inputs = model.get_layer('Encoder_Input').input\n\ninf_encoder_embedding_layer = model.get_layer('News_Embedding')\ninf_encoder_embeddings = inf_encoder_embedding_layer(inf_encoder_inputs)\n\ninf_encoder_lstm1 = model.get_layer('Encoder_LSTM_1')\ninf_encoder_lstm1_output, _, _, = inf_encoder_lstm1(inf_encoder_embeddings)\n\ninf_encoder_lstm2 = model.get_layer('Encoder_LSTM_2')\ninf_encoder_lstm2_output, _, _ = inf_encoder_lstm2(inf_encoder_lstm1_output)\n\ninf_encoder_lstm3 = model.get_layer('Encoder_LSTM_3')\ninf_encoder_lstm3_output, inf_state_h, inf_state_c = inf_encoder_lstm2(inf_encoder_lstm2_output)\n\ninf_final_encoder_outputs = [inf_encoder_lstm3_output, inf_state_h, inf_state_c]\n\ninf_encoder_model  = Model(inf_encoder_inputs, inf_final_encoder_outputs)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:58.576997Z","iopub.execute_input":"2023-12-10T08:33:58.577554Z","iopub.status.idle":"2023-12-10T08:33:59.675868Z","shell.execute_reply.started":"2023-12-10T08:33:58.577456Z","shell.execute_reply":"2023-12-10T08:33:59.674593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inf_decoder_inputs = model.get_layer('Decoder_Input').input\n\ninf_final_encoder_output = Input(shape=(CONSTANTS[\"max_news_length\"], CONSTANTS[\"latent_dim\"],), name='Encoder_Final_Output')\ninf_final_encoder_state_h = Input(shape=(CONSTANTS[\"latent_dim\"],), name='Encoder_Final_Hidden_State')\ninf_final_encoder_state_c = Input(shape=(CONSTANTS[\"latent_dim\"],), name='Encoder_Final_Cell_State')\ninf_final_encoder_states = [inf_final_encoder_state_h, inf_final_encoder_state_c]\n\ninf_decoder_embedding_layer = model.get_layer('Title_Embedding')\ninf_decoder_embeddings = inf_decoder_embedding_layer(inf_decoder_inputs)\n\ninf_decoder_lstm = model.get_layer('Decoder_LSTM')\ninf_decoder_lstm_output, inf_decoder_lstm_state_h, inf_decoder_lstm_state_c = inf_decoder_lstm(inf_decoder_embeddings, initial_state=inf_final_encoder_states)\n\ninf_final_decoder_states = [inf_decoder_lstm_state_h, inf_decoder_lstm_state_c]\n\ninf_bahdanau_attention_layer = model.get_layer('Bahdanau_Attention')\ninf_context_vectors, _ = inf_bahdanau_attention_layer([inf_final_encoder_output, inf_decoder_lstm_output])\n\ninf_decoder_concat_layer = model.get_layer('Concatenate_Layer')\ninf_decoder_concat_output = inf_decoder_concat_layer([inf_decoder_lstm_output, inf_context_vectors])\n\ninf_dense_layer = model.get_layer('Softmax_Layer')\ninf_final_decoder_output = inf_dense_layer(inf_decoder_concat_output)\n\ninf_decoder_model  = Model([inf_decoder_inputs, inf_final_encoder_output] + inf_final_encoder_states, [inf_final_decoder_output] + inf_final_decoder_states)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:33:59.677391Z","iopub.execute_input":"2023-12-10T08:33:59.677744Z","iopub.status.idle":"2023-12-10T08:34:00.064250Z","shell.execute_reply.started":"2023-12-10T08:33:59.677715Z","shell.execute_reply":"2023-12-10T08:34:00.062993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import string\nimport re\nfrom nltk.corpus import stopwords\nnep_stopwrods = stopwords.words(\"nepali\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:34:00.073779Z","iopub.execute_input":"2023-12-10T08:34:00.074203Z","iopub.status.idle":"2023-12-10T08:34:00.080640Z","shell.execute_reply.started":"2023-12-10T08:34:00.074172Z","shell.execute_reply":"2023-12-10T08:34:00.079351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_emojis_english_and_numbers(data):\n    '''\n    Removes emojis, non-nepali texts and numbers from the given text\n    '''\n    # Removes emoji from given data\n    emoj = re.compile(\"[\"\n        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n        u\"\\U00002500-\\U00002BEF\"  # chinese char\n        u\"\\U00002702-\\U000027B0\"\n        u\"\\U00002702-\\U000027B0\"\n        u\"\\U000024C2-\\U0001F251\"\n        u\"\\U0001f926-\\U0001f937\"\n        u\"\\U00010000-\\U0010ffff\"\n        u\"\\u2640-\\u2642\" \n        u\"\\u2600-\\u2B55\"\n        u\"\\u200d\"\n        u\"\\u23cf\"\n        u\"\\u23e9\"\n        u\"\\u231a\"\n        u\"\\ufe0f\"  # dingbats\n        u\"\\u3030\"\n                      \"]+\", re.UNICODE)\n    res = re.sub(emoj, '', data)\n    res = re.sub('[0-9]+', '', res)\n    return re.sub('[a-zA-Z]', '', res)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:34:00.082555Z","iopub.execute_input":"2023-12-10T08:34:00.083089Z","iopub.status.idle":"2023-12-10T08:34:00.096122Z","shell.execute_reply.started":"2023-12-10T08:34:00.083023Z","shell.execute_reply":"2023-12-10T08:34:00.094759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(data, is_title=False):\n    if type(data) == float:\n        return data\n    data = data.replace(\"-\", \" \").replace(\"—\", \" \").replace(\"‘\", \" \").replace(\"’\", \" \").replace(\"।\", \" \").replace(\"–\", \" \").replace(\"“\", \" \").replace(\"”\", \" \") .replace(\"\\n\", \" \").replace(\"–\", \" \").replace(\"ः\", \" \")\n    no_extra_spaces = \" \".join(data.split())\n    no_emoji_english_numbers = remove_emojis_english_and_numbers(no_extra_spaces)\n    no_punc = \"\".join([char for char in no_emoji_english_numbers if char not in (string.punctuation)])\n    extra = \" \".join(no_punc.split())\n    # Remove stopwords from title only\n    if not is_title:\n        no_stopwords = [word for word in extra.split() if word.strip() not in nep_stopwrods]\n        return \" \".join(no_stopwords)\n    else:\n        return extra\nprint(\"नेपाल क्रिकेट सङ्घ (क्यान) ले बन्द प्रशिक्षणका\")\npreprocess_text(\"नेपाल क्रिकेट सङ्घ (क्यान) ले बन्द प्रशिक्षणका\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:34:00.098253Z","iopub.execute_input":"2023-12-10T08:34:00.099099Z","iopub.status.idle":"2023-12-10T08:34:00.121356Z","shell.execute_reply.started":"2023-12-10T08:34:00.099029Z","shell.execute_reply":"2023-12-10T08:34:00.119915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## COMPUTE BLEU SCORE FOR THE TEST SET","metadata":{}},{"cell_type":"code","source":"def sequence_to_words(sequence, tokenizer):\n    words = tokenizer.sequences_to_texts([sequence])[0]\n    return \" \".join(words.split()[1:-1])","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:34:00.123126Z","iopub.execute_input":"2023-12-10T08:34:00.124160Z","iopub.status.idle":"2023-12-10T08:34:00.131527Z","shell.execute_reply.started":"2023-12-10T08:34:00.124111Z","shell.execute_reply":"2023-12-10T08:34:00.130070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_tokenizer.word_index['विनिमय']","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:34:00.133564Z","iopub.execute_input":"2023-12-10T08:34:00.134103Z","iopub.status.idle":"2023-12-10T08:34:00.149936Z","shell.execute_reply.started":"2023-12-10T08:34:00.134051Z","shell.execute_reply":"2023-12-10T08:34:00.148400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_tokenizer.index_word[20]","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:34:00.151771Z","iopub.execute_input":"2023-12-10T08:34:00.152254Z","iopub.status.idle":"2023-12-10T08:34:00.161861Z","shell.execute_reply.started":"2023-12-10T08:34:00.152216Z","shell.execute_reply":"2023-12-10T08:34:00.160384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def greedy_summarize(news_sequence, X_tokenizer, y_tokenizer, max_title_length=21, sos_token=\"sos\", eos_token=\"eos\"):\n        \n    encoder_output, h_t_minus_1, c_t_minus_1 = inf_encoder_model.predict(news_sequence)\n\n    title_sequence = []\n    \n    # Generate empty target sequence of length 1.\n    word_n_minus_1 = np.zeros((1,1))\n    \n    # Populate the first word of target sequence with the start word.\n    word_n_minus_1[0, 0] = y_tokenizer.word_index[sos_token]\n\n    # Decode the sequence one token at a time.\n    for i in range(max_title_length):\n        \n        # Determine the next word.\n        decoder_output, h_t, c_t = inf_decoder_model.predict([word_n_minus_1, encoder_output, h_t_minus_1, c_t_minus_1])\n        prob_dist = decoder_output[0][-1]\n        word_n_index = np.argmax(prob_dist)\n        if word_n_index == 0:\n            h_t_minus_1, c_t_minus_1 = h_t, c_t\n            continue\n            \n        word_n = y_tokenizer.index_word[word_n_index]\n        \n        if word_n == eos_token:\n            break\n            \n        # Update the previous sequence (of length 1).\n        word_n_minus_1 = np.zeros((1,1))\n        word_n_minus_1[0, 0] = word_n_index\n        \n        title_sequence.append(word_n)\n        \n#         print(title_sequence)\n        \n        # Update the internal states for the next time step t+1.\n        h_t_minus_1, c_t_minus_1 = h_t, c_t\n\n    # Return the generated sequence as sentence\n    return \" \".join(title_sequence)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:34:00.164147Z","iopub.execute_input":"2023-12-10T08:34:00.164948Z","iopub.status.idle":"2023-12-10T08:34:00.178238Z","shell.execute_reply.started":"2023-12-10T08:34:00.164882Z","shell.execute_reply":"2023-12-10T08:34:00.176773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def summarize_with_beam_search(news_sequence, X_tokenizer, y_tokenizer, beam_width=3, alpha=0.8, sos_token='sos', eos_token='eos', max_title_length=21):\n\n    encoder_output, h_t_minus_1, c_t_minus_1 = inf_encoder_model.predict(news_sequence)\n    \n    # Initialize the beam of sequences.\n    # Initially we start with the SOS_TOKEN\n    beam = [[0.0, [y_tokenizer.word_index[sos_token]]]]\n    \n    # Decode the sequence one token at a time.\n    for i in range(max_title_length):\n\n        # Expand the beam.\n        expanded_beam = []\n        for log_probability_score, sequence in beam:\n            if (sequence[-1] != y_tokenizer.word_index[eos_token]):\n                \n                # Generate empty target sequence of length 1.\n                word_n_minus_1 = np.zeros((1,1))\n    \n                # Populate the first word of target sequence with the start word.\n                word_n_minus_1[0, 0] = sequence[-1]\n                \n                decoder_output, h_t, c_t = inf_decoder_model.predict([word_n_minus_1, encoder_output, h_t_minus_1, c_t_minus_1])\n\n                prob_dist = decoder_output[0, -1, :]\n\n                # Generate all possible next tokens for the sequence.\n                for word_n_index in range(len(prob_dist)):\n                    expanded_beam.append([log_probability_score + np.log(prob_dist[word_n_index]), sequence + [word_n_index]])\n\n        # Prune the beam to get the top-K\n        beam = sorted(expanded_beam, key=lambda x: x[0], reverse=True)[:beam_width]\n        \n        # Check if all of the top-K sequences have encountered the EOS token.\n        # Or all of the top-K sequences have length > max_title_length\n        if all(sequence[-1] == y_tokenizer.word_index[eos_token] for prob, sequence in beam):\n            ''' This section indicates the top-K sequences has been generated '''\n            ''' Finally, we perform length normalization on the log proability score of each sequence before exiting '''\n            for i in range(len(beam)):\n                beam[i][1] = beam[i][1][1:] # Remove the SOS_TOKEN from the start\n                beam[i][0] /= (len(beam[i][1])**alpha) # Perform length normalization       \n            beam = sorted(beam, key=lambda x: x[0], reverse=True)\n            break\n\n        # Update the internal states for the next time step t+1.\n        h_t_minus_1, c_t_minus_1 = h_t, c_t\n\n    # Return the sequence with the highest score from the beam as sentence.\n    return sequence_to_words(beam[0][1], y_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:34:00.179865Z","iopub.execute_input":"2023-12-10T08:34:00.180269Z","iopub.status.idle":"2023-12-10T08:34:00.199135Z","shell.execute_reply.started":"2023-12-10T08:34:00.180236Z","shell.execute_reply":"2023-12-10T08:34:00.197762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def summarize_with_beam_search_ap_rp_pruning(news_sequence, X_tokenizer, y_tokenizer, beam_width=3, alpha=0.8, sos_token='sostok', eos_token='eostok', rp=0.5, ap=2.5, max_title_length=21):\n\n#     encoder_output, h_t_minus_1, c_t_minus_1 = inf_encoder_model.predict(news_sequence)\n\n#     # Initialize the beam of sequences.\n#     # Initially we start with the SOS_TOKEN\n#     beam = [(0.0, [y_tokenizer.word_index[sos_token]])]\n\n#     # Decode the sequence one token at a time.\n#     for i in range(max_title_length):\n\n#         # Expand the beam.\n#         expanded_beam = []\n#         for log_probability_score, sequence in beam:\n#             if (sequence[-1] != y_tokenizer.word_index[eos_token]):\n                \n#                 # Generate empty target sequence of length 1.\n#                 word_n_minus_1 = np.zeros((1,1))\n    \n#                 # Populate the first word of target sequence with the start word.\n#                 word_n_minus_1[0, 0] = sequence[-1]\n                \n#                 decoder_output, h_t, c_t = inf_decoder_model.predict([word_n_minus_1, encoder_output, h_t_minus_1, c_t_minus_1])\n\n#                 prob_dist = decoder_output[0, -1, :]\n\n#                 # Generate all possible next tokens for the sequence.\n#                 for word_n_index in range(len(prob_dist)):\n#                     expanded_beam.append((log_probability_score + np.log(prob_dist[word_n_index]), sequence + [word_n_index]))\n\n#         # Prune the beam to get the top-K\n#         beam = sorted(expanded_beam, key=lambda x: x[0], reverse=True)[:beam_width]\n        \n#         # Check if all of the top-K sequences have encountered the EOS token.\n#         # Or all of the top-K sequences have length > max_title_length\n#         if all(sequence[-1] == y_tokenizer.word_index[eos_token] for prob, sequence in beam):\n#             ''' This section indicates the top-K sequences has been generated '''\n#             ''' Finally, we perform length normalization on the log proability score of each sequence before exiting '''\n#             for i in range(len(beam)):\n#                 beam[i][1] = beam[i][1][1:] # Remove the SOS_TOKEN from the start\n#                 beam[i][0] /= (len(beam[i][1])**alpha) # Perform length normalization       \n#             beam = sorted(beam, key=lambda x: x[0], reverse=True)\n#             break\n        \n#         ''' Prune the beam using Relative Threshold Pruning and Absolute Threshold Pruning '''\n#         max_candidate_score = beam[0][0]\n        \n#         ''' Relative Threshold Pruning '''\n#         beam = [(score, sequence) for score, sequence in beam if score > ((1+rp) * max_candidate_score)]\n        \n#         ''' Absolute Threshold Pruning '''\n#         beam = [(score, sequence) for score, sequence in beam if score > (max_candidate_score - ap)]\n        \n#         print(len(beam))\n            \n#         # Update the internal states for the next time step t+1.\n#         h_t_minus_1, c_t_minus_1 = h_t, c_t\n\n#     # Return the sequence with the highest score from the beam as sentence.\n#     return sequence_to_words(beam[0][1], y_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:34:00.201630Z","iopub.execute_input":"2023-12-10T08:34:00.202113Z","iopub.status.idle":"2023-12-10T08:34:00.217493Z","shell.execute_reply.started":"2023-12-10T08:34:00.202078Z","shell.execute_reply":"2023-12-10T08:34:00.216161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news = []\nreference_titles = []\npredicted_titles_greedy = []\npredicted_titles_beam = []\npredicted_titles_beam_prune = []\n\n\nfor index, each_seq in enumerate(X_test_pad_seq[:10000]):\n    news.append(sequence_to_words(each_seq, tokenizer=X_tokenizer))\n    reference_titles.append(sequence_to_words(y_test_padded_seq[index], tokenizer=y_tokenizer))","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:34:00.219309Z","iopub.execute_input":"2023-12-10T08:34:00.219753Z","iopub.status.idle":"2023-12-10T08:34:07.137921Z","shell.execute_reply.started":"2023-12-10T08:34:00.219713Z","shell.execute_reply":"2023-12-10T08:34:07.136634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:34:07.139200Z","iopub.execute_input":"2023-12-10T08:34:07.139586Z","iopub.status.idle":"2023-12-10T08:34:07.153520Z","shell.execute_reply.started":"2023-12-10T08:34:07.139552Z","shell.execute_reply":"2023-12-10T08:34:07.151997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(y_test[\"title_cut\"])[5]","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:34:07.155458Z","iopub.execute_input":"2023-12-10T08:34:07.156062Z","iopub.status.idle":"2023-12-10T08:34:07.178898Z","shell.execute_reply.started":"2023-12-10T08:34:07.156013Z","shell.execute_reply":"2023-12-10T08:34:07.176796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_tokenizer.sequences_to_texts([y_test_padded_seq[5]])[0].split()[1:-1]","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:34:07.180878Z","iopub.execute_input":"2023-12-10T08:34:07.181300Z","iopub.status.idle":"2023-12-10T08:34:07.189480Z","shell.execute_reply.started":"2023-12-10T08:34:07.181268Z","shell.execute_reply":"2023-12-10T08:34:07.188161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_padded_seq[5]","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:34:07.191265Z","iopub.execute_input":"2023-12-10T08:34:07.191752Z","iopub.status.idle":"2023-12-10T08:34:07.204381Z","shell.execute_reply.started":"2023-12-10T08:34:07.191707Z","shell.execute_reply":"2023-12-10T08:34:07.203142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_tokenizer.word_index[\"घट्दै\"]","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:34:07.208899Z","iopub.execute_input":"2023-12-10T08:34:07.209288Z","iopub.status.idle":"2023-12-10T08:34:07.222574Z","shell.execute_reply.started":"2023-12-10T08:34:07.209258Z","shell.execute_reply":"2023-12-10T08:34:07.221256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:34:07.224190Z","iopub.execute_input":"2023-12-10T08:34:07.224716Z","iopub.status.idle":"2023-12-10T08:34:07.233038Z","shell.execute_reply.started":"2023-12-10T08:34:07.224677Z","shell.execute_reply":"2023-12-10T08:34:07.230885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_taken = {}","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:34:07.235203Z","iopub.execute_input":"2023-12-10T08:34:07.236003Z","iopub.status.idle":"2023-12-10T08:34:07.245613Z","shell.execute_reply.started":"2023-12-10T08:34:07.235966Z","shell.execute_reply":"2023-12-10T08:34:07.244246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''' GREEDY DECODING '''\ngreedy_start = time.time()\nfor index, each_seq in enumerate(X_test_pad_seq[:10000]):\n    predicted_titles_greedy.append(greedy_summarize(each_seq.reshape(1,CONSTANTS[\"max_news_length\"]), X_tokenizer, y_tokenizer))\ngreedy_end = time.time()\ntime_taken[\"GREEDY\"] = (greedy_end - greedy_start) / 60 # In minutes","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-10T08:34:07.247123Z","iopub.execute_input":"2023-12-10T08:34:07.247508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(zip(reference_titles, predicted_titles_greedy))[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''' BEAM SEARCH DECODING '''\nbeam_start = time.time()\nfor index, each_seq in enumerate(X_test_pad_seq[:10000]):\n    predicted_titles_beam.append(summarize_with_beam_search(each_seq.reshape(1,CONSTANTS[\"max_news_length\"]), X_tokenizer, y_tokenizer))\nbeam_end = time.time()\ntime_taken[\"BEAM\"] = (beam_end - beam_start) / 60 # In minutes    ","metadata":{"_kg_hide-output":true,"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(zip(reference_titles, predicted_titles_beam))[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ''' BEAM SEARCH DECODING WITH PRUNING '''\n# beam_prune_start = time.time()\n# for index, each_seq in enumerate(X_train_pad_seq[:10]):\n#     predicted_titles_beam_prune.append(summarize_with_beam_search_ap_rp_pruning(each_seq.reshape(1,max_news_length), X_tokenizer, y_tokenizer))\n# beam_prune_end = time.time()\n# time_taken[\"BEAM PRUNE\"] = (beam_prune_end - beam_prune_start) / 60 # In minutes    ","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list(zip(reference_titles, predicted_titles_beam_prune))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_taken","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## COMPUTE BLEU AND ROUGE SCORES FOR GENERATED TITLES","metadata":{}},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu\nfrom nltk.translate.bleu_score import SmoothingFunction\nsmoothie = SmoothingFunction().method4\n\ndef compute_bleu_metric(reference: list, predicted: list) -> float:\n    '''\n    Computes the BLEU metric given a set of refraence and predicted sequences of words\n    \n    :param list(str) refrence: List of refrence sequences. Eg: [\"Hi I am jane doe\", \"i am from italy\"]    \n    :param list(str) predicted: List of predicted sequences. Eg: [\"i jane doe\", \"i was born and raised in sicily\"]\n    :return: The BLEU score for the predicted sequences.\n    '''\n    return corpus_bleu([[value.split()] for value in reference], [value.split() for value in predicted], smoothing_function=smoothie, weights=(0.25, 0.25, 0.25, 0.25))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bleu_scores = {}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.array(predicted_titles_beam).shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bleu_scores[\"GREEDY\"] = compute_bleu_metric(reference_titles, predicted_titles_greedy)\nbleu_scores[\"BEAM\"] = compute_bleu_metric(reference_titles, predicted_titles_beam)\n# bleu_scores[\"BEAM PRUNE\"] = compute_bleu_metric(reference_titles, predicted_titles_beam_prune)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bleu_scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install rouge","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from rouge import Rouge\nrouge = Rouge()\n\ndef compute_rouge_metric(reference: list, predicted: list) -> dict:\n    '''\n    Computes Rogue-1, Rouge-2 and Rouge-L metric given a set of refraence and predicted sequences of words\n    \n    :param list(str) refrence: List of refrence sequences. Eg: [\"Hi I am jane doe\", \"i am from italy\"]    \n    :param list(str) predicted: List of predicted sequences. Eg: [\"i jane doe\", \"i was born and raised in sicily\"]\n    :return: The rouge-1,2,L scores for the predicted sequences.\n    '''\n    scores = rouge.get_scores(predicted, reference, avg=True)\n    return {\n        \"Rouge-1\": scores['rouge-1']['f'],\n        \"Rouge-2\": scores['rouge-2']['f'],\n        \"Rouge-L\": scores['rouge-l']['f']\n    }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rouge_scores = {}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rouge_scores[\"GREEDY\"] = compute_rouge_metric(reference_titles, predicted_titles_greedy)\nrouge_scores[\"BEAM\"] = compute_rouge_metric(reference_titles, predicted_titles_beam)\n# rouge_scores[\"BEAM PRUNE\"] = compute_rouge_metric(reference_titles, predicted_titles_beam_prune)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rouge_scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}